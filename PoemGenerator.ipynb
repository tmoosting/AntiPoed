{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  AntiPoed Logbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational Creativity - Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Titus Oosting (s2683466)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "In this logbook I describe the process of building an application that writes novel poems. The final output can be seen in the Little AntiPoed Poetry Collection. \n",
    "\n",
    "AntiPoed is a combinational-creative application that fuses the work of a base poet with that of the poets they inspired. Inspiration, with a non-linear twist. To do so, it downloads poems from a website then processes the text. AntiPoed employs the spaCy NLP toolset to produce new works of creative art. \n",
    "\n",
    "This logbook contains the following sections:\n",
    "* [Introduction](#Introduction)\n",
    "* [Technical Tools and Implementation](#Technical-Tools-&-Implementation)\n",
    "* [Creative Reflection](#Creative-Reflection)\n",
    "* [Future Development](#Future-Development)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "What does creativity mean when talking about poetry? Is it form, theme or vocabulary? How does independent creative inspiration measure against external, time-bound influence?\n",
    "\n",
    "The skill, dedication and vision of great poets has driven creativity in language and art. In doing so, they will always stand on the linguistic, stylistic and thematic shoulders of their predecessors. Poetic influence is hard to measure but fundamental to the creative process.\n",
    "\n",
    "The nature of time dictates that this process of inspiration operates in one direction. Themes are debased and transfigured; linguistic liberty establishes new norms; words are reused and reimagined.\n",
    "\n",
    "Can we imagine this linear flow of poetic creation in a more circular form? What would a budding Edgar Allan Poe, who died two years before Oscar Wilde was born, take for linguistic and thematic inspiration from Oscar that he himself explicitly inspired? How might his gloomy themes, expounded through his mastery of language and punctation, be transformed through the modern lexicon of a near-contemporary poet that he inspired, such as Maya Angelou?\n",
    "\n",
    "AntiPoed reconfigures these micro-antipodes, subsets of poetic cause and effect, and creates works of poetry that transcend the vagaries of linear time and loss. \n",
    "\n",
    "The poems in the Little AntiPoed Poetry Collection are an exploration of what Poe's poems may have been like were he to be influenced by his successors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Tools & Implementation\n",
    "\n",
    "\n",
    "#### Origin and Credits\n",
    "[Benjamín Durán's scraper and replacer](https://towardsdatascience.com/creating-a-poems-generator-using-word-embeddings-bcc43248de4f) inspired the use of spaCy's [Word Vectors and Semantic Similarity feature](https://spacy.io/usage/vectors-similarity) and offered easily-implementable-code for scraping a specific site for sets of poems of specific poets.\n",
    "I used and transformed parts of this code to download and save an inspiring set of poems ('inspirers', which in the context of AntiPoed are, of course, poets that were inspired by the original poet) and the base poems for the poetry collection (written by the 'inspiree').\n",
    "\n",
    "### Technical Overview\n",
    "\n",
    "#### Base poems\n",
    "\n",
    "The inspiree's name is given as variable `inspiree`.  For each of the poems that are outputted in a single run of the application, their amount set by `len_poetry_collection`, a base poem is chosen from this poet's existing poems. These poems are then each split into sentences which are subsequently modified with inspirations from the inspiring set using SpaCy's tools. \n",
    "\n",
    "#### Selection of poets\n",
    "\n",
    "For the supplied poetry collection, I used two inspirers - poets that explicitly stated the influence on their works by Edgar Allan Poe. The application allows (at a cost in performance) any amount of inspirers to be included in the set, and the inspiree can also be changed. These names are entered into the `inspirers` variable. The [website used here](http://mypoeticside.com) conveniently lists a the inspirations and inspirees for each author. \n",
    "\n",
    "#### Inspiring Set\n",
    "\n",
    "The full set of poems of each of the inspirers is similarly split into sentences. These sentences are then scanned using spaCy's [part-of-speech tagging](https://spacy.io/usage/linguistic-features#pos-tagging) to fill three lists of strings: one for nouns, one for adjectives, and one for proper nouns. This could be expanded to include other entities or additionaly structural elements. \n",
    "\n",
    "#### antipoed_poem_maker \n",
    "\n",
    "For each base poem, each of its sentences is scanned for the same grammar types that we collected for the inspiring set: nouns, adjectives and proper nouns. These are replaced by the best-scoring option from the Inspiring Set, using spaCy's [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity). \n",
    "For reasons of both randomness and performance, a sample of the Inspiring Set's words are used, rather than the entire list. The sample size can be controlled using `size_inspiring_nouns_set` (/adjs/proper_nouns). \n",
    "\n",
    "\n",
    "### Outputting\n",
    "\n",
    "#### Poem Title\n",
    "AntiPoed goes beyond mere words to [capture the emotions](https://pypi.org/project/text2emotion/) of its digital products. These emotions are outputted in a non-traditional but visually eloquent image-title. `'Happy', 'Angry', 'Surprise', 'Sad', 'Fear'` are respectively mapped to `'orange', 'firebrick', 'cyan', 'slateblue', 'thistle'`. The width of the bars represents the proportion of a particular emotion.\n",
    "\n",
    "#### Title Page  -> Network Graph\n",
    "I created a similarity matrix of words relative to each other for each of the adjectives of `inspiring_adjs`. The outputted csv file I then edited in [Gephi](https://gephi.org/) to create a network graph, which serves to give a visual-thematic impression of the word library that the collection's poems are based on. It serves to give a feel and impression of the AntiPoed method. \n",
    "\n",
    "#### Poem Display\n",
    "\n",
    "The list of sentences for each poem is joined back together into one text, adding a capitalization for the very first letter of the poem and a period to close it. The markdown display() function is used for formatting. See Future Development for a further note on punctuation in particular. \n",
    "\n",
    "\n",
    "### spaCy features\n",
    "\n",
    "* [Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity)\n",
    "* [Part-of-speech Tagging](https://spacy.io/usage/linguistic-features#pos-tagging)\n",
    "\n",
    "\n",
    "### spaCy model\n",
    "\n",
    "* spaCy is loaded with the variable `nlp_model`, where its dataset can be `en_core_web_sm`, `en_core_web_md`, `en_core_web_lg`, the latter of which is most accurate and about 787mb in size. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creative Reflection\n",
    "\n",
    "Imagine a scholar of Oscar Wilde's poetry. \n",
    "\n",
    "Ask them to capture the writer's style, and the distinctiveness of his poetry, and find some ways to transpose these onto the poems of one of his explicit inspirers - those of Edgar Allan Poe. \n",
    "\n",
    "Can we call the resulting work - the elegant blend of styles - or Frankenstein's poetic monster - a creative work of art? Is there novelty beyond the combinational if the inspiring set is limited to the templates and words of just two previous creators?\n",
    "\n",
    "The efforts of our individual scholar would no doubt be considered creative in their own right. Even though they construct their work from such specific building blocks, they have applied their own interpretation and inspiration into producing a novel product: a poem that has never been written before. \n",
    "\n",
    "A computer program has, perhaps, a higher threshold to cross to 'feel safe' in its perceived creative credentials. If our scholar were to change only one word from an existing poem, we can imagine some deep reason for and implication of such a change. A piece of code providing a similar output is more likely to be accused of devolution and arbitrariness.\n",
    "\n",
    "But AntiPoed is no less a creator than our esteemed scholar. We don't label any such attempt made by a human to be non-creative (providing they make a fair effort), but should we not hold non-human entities to the same standard? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Development\n",
    "\n",
    "### Automation\n",
    "#### Improved Poet Crawler\n",
    "* Poets that are inspired by the base poet ('inspirers' for this application) are currently set manually with an environment variable. With a little additional code, these could be collected automatically from the website's list of inspirees. In this case, a variable should be offered that caps the amount to be downloaded (for performance reasons).\n",
    "\n",
    "### Poem Generation - Improving the Current Replacement Method\n",
    "#### Fixes\n",
    "* Capitalize single 'i' in the poems\n",
    "* Avoid plural / singular combination of nouns (they tend to score high on similarity)\n",
    "\n",
    "#### Rhyming\n",
    "* Edgar Allan Poe employed rhyming schemes in most of his poetry. AntiPoed ignores these rhymes when it re-inspires words. By using a tool such as [pronouncing](https://pypi.org/project/pronouncing/), replacement words could be scored and chosen not only on vector-similarity but also on rhyming quality.\n",
    "\n",
    "####  Named Entity Recognition\n",
    "* Proper noun replacements are based on similarity score, but could be more accurately replaced using spaCy's [Named Entity Recognition](https://spacy.io/usage/linguistic-features#named-entities) feature. This tool recognizes [various types](https://spacy.io/api/annotation#named-entities) of proper nouns, and would allow replacement within those types instead of across the entire spectrum.  \n",
    "\n",
    "####  Punctuation\n",
    "* Edgar Allan Poe was particular about his use of punctuation, and had [strong opinions](https://www.newsandtimes.com/2016/12/poe-and-the-all-important-dash/) on its role (contemporary and in general) in the English language. Our sentence-splitter makes rough work of these efforts, and does not read them in any significant way, nor does it have much logic for outputting punctuation. Searching for something like 'nlp punctuation' mainly returns results that help get rid of / clean up punctuation, but there are plenty of ways to read and filter the relevant symbols, including in spaCy, and some logic could be written to deduce and recreate punctuation styles. \n",
    "\n",
    "### Poem Generation - Additional Functionalities to Consider\n",
    "####  Verbs and Grammar\n",
    "* A primary critique of AntiPoed might be its lack of ability to create poems that are structurally 'brand new', as it doesn't modify the base poems' structure beyond the meter. It might be desirable for a future version to do some derivation of structure from the inspirers. While verbs could easily be replaced by applying the same trick as AntiPoed does for nouns / adjectives / proper nouns, we can imagine an even bigger impact on the poem's coherence, so some additional logic would be desirable. \n",
    "\n",
    "####  Mutations\n",
    "* Additional variation both in structure and meaning could be made through random specific events, comparable to mutations in a genetic algorithm. Verses could be shuffled around, deleted, or entirely new verses could be added. Specific words could be changed through separate logic. Each of these steps would ideally have some logic or meaning behind it, where tools for sentiment analysis, image recognition (for structure) and grammar rules could be useful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "* fix titles placement\n",
    "* fix poem text\n",
    "\n",
    "* Make Network graph if possible\n",
    "* Presententaion(title page has network graph of words) - centering, font?  / PDF or webpage?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a23159303902>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMarkdown\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import re\n",
    "import spacy\n",
    "from IPython.display import Image, display, Markdown\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import text2emotion as te\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppURLopener(urllib.request.FancyURLopener): \n",
    "    version = \"Mozilla/82.0.2\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AntiPoed Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AntiPoed:\n",
    "    poetry_collection_name: str = \"Little AntiPoed Poetry Collection\"\n",
    "    len_poetry_collection: int = 4\n",
    "    inspiree: str =  \"edgar-allan-poe-poems\" # inspiree\n",
    "    inspirers: List =  field(default_factory=lambda: [\"maya-angelou-poems\", \"oscar-wilde-poems\"] )\n",
    "    source_website: str = 'https://mypoeticside.com/poets/'\n",
    "    nlp_model =  spacy.load(\"en_core_web_lg\")\n",
    "    load_inspiring_set:bool = False\n",
    "    size_inspiring_nouns_set: int = 60\n",
    "    size_inspiring_adjs_set: int = 60\n",
    "    size_inspiring_proper_nouns_set: int = 60\n",
    "    inspiring_nouns: list = field(default_factory=list)\n",
    "    inspiring_adjs: list = field(default_factory=list)\n",
    "    inspiring_proper_nouns: list = field(default_factory=list)\n",
    "    base_poems: list = field(default_factory=list)\n",
    "    new_poems: list = field(default_factory=list)   \n",
    "        \n",
    "    \n",
    "    \n",
    "    def read_poems_to_csv(self, poet: str)->None:\n",
    "        \"\"\"Take a poet's name & read poems to csv.\"\"\"\n",
    "        data = self.opener.open(self.source_website + poet).read().decode()\n",
    "        soup =  BeautifulSoup(data, 'html.parser')\n",
    "        poem_list = soup.find(class_= \"list-poems\")\n",
    "        links = poem_list.findAll('a')\n",
    "        results = [\"https:\"+link.get('href') for link in links]\n",
    "        titles = []\n",
    "        corpus = []\n",
    "        for page in results:\n",
    "            data = self.opener.open(page).read().decode()\n",
    "            soup = BeautifulSoup(data, 'html.parser')\n",
    "            title = soup.find(class_='title-poem')\n",
    "            poem = soup.find(class_='poem-entry')\n",
    "            titles.append(title.getText())\n",
    "            corpus.append(poem.find('p').getText())\n",
    "            poems = pd.DataFrame({'title' : titles,'text' : corpus})\n",
    "            poems.to_csv('poems_' + poet.replace('-poems','')+ '.csv')\n",
    "\n",
    "        \n",
    "    def inspiring_nouns_adjs(self, file_path:str, split=r\"\\n\"):\n",
    "            \"\"\"Gathers the nouns & adjectives for inspiring set.\"\"\"\n",
    "            df_poems = pd.read_csv(file_path)\n",
    "            number_poems = df_poems.shape[0]\n",
    "\n",
    "            for i in range(number_poems):\n",
    "                text = df_poems.text[i]\n",
    "                #dictionary to replace unwanted elements\n",
    "                replace_dict = {'?«' :  '«', '(' :  '', ')' : '', ':' : ',', '.' : ',', \n",
    "                    ',,,' : ',', '\"': '', '\\r': ''}\n",
    "                for x,y in replace_dict.items():\n",
    "                    text = text.replace(x, y)\n",
    "                text = text.lower()   \n",
    "                #split into sentences\n",
    "                sentences = re.split(split, text)\n",
    "                for sentence in sentences:\n",
    "                    doc = self.nlp_model(sentence)\n",
    "                    for token in doc:\n",
    "                        if token.pos_ =='NOUN':\n",
    "                            self.inspiring_nouns.append(token.text)\n",
    "                        elif token.pos_ == 'ADJ':\n",
    "                            self.inspiring_adjs.append(token.text)\n",
    "                        elif token.pos_ == 'PROPN':\n",
    "                            self.inspiring_proper_nouns.append(token.text)\n",
    "                            \n",
    "    \n",
    "    \n",
    "    def prepare_inspiring_set(self) ->None:\n",
    "        \"\"\"Gets & prepares the inspiring set for poem generation.\"\"\"\n",
    "        \n",
    "        list_poets = self.inspirers + [self.inspiree]\n",
    "        poem_files = [f'poems_'+ poet.replace('-poems','') + '.csv' for poet in list_poets]\n",
    "        \n",
    "        # download data\n",
    "        if self.load_inspiring_set:\n",
    "            self.opener = AppURLopener()\n",
    "            for poet in list_poets:\n",
    "                self.read_poems_to_csv(poet)\n",
    "        \n",
    "        for poet_file in poem_files:\n",
    "            self.inspiring_nouns_adjs(file_path=poet_file, split=r\"\\n\")\n",
    "    \n",
    "    def base_poem_prepare(self, poem, split=r\"\\n\") ->dict:\n",
    "        \"\"\"Select base poem from inspiree set & prepare template\"\"\"\n",
    "        text = poem['text'].iloc[0]\n",
    "        #dictionary to replace unwanted elements\n",
    "        replace_dict = {'?«' :  '«', '(' :  '', ')' : '', ':' : ',', '.' : ',', \n",
    "            ',,,' : ',', '\"': '', '\\r': ''}\n",
    "        for x,y in replace_dict.items():\n",
    "            text = text.replace(x, y)\n",
    "        text = text.lower()   \n",
    "        #split into sentences\n",
    "        base_sentences = re.split(split, text)\n",
    "        return {\"title\": poem['title'].iloc[0], \"poem\": base_sentences }\n",
    "    \n",
    "    def antipoed_poem_maker(self, base_poem:dict)-> dict:\n",
    "        \"\"\"Makes a new poem for each of the base set.\"\"\"\n",
    "        sentences = base_poem[\"poem\"].copy()\n",
    "        for index, sentence in enumerate(sentences):\n",
    "            doc = self.nlp_model(sentence)\n",
    "            new_sentence = sentence\n",
    "            for token in doc:\n",
    "                if token.pos_ == 'NOUN':\n",
    "                    sim_dict = {}\n",
    "                    for noun in random.sample(self.inspiring_nouns, self.size_inspiring_nouns_set):\n",
    "                        noun = self.nlp_model(noun)\n",
    "                        similarity = self.nlp_model(token.text).similarity(noun)\n",
    "                        sim_dict[noun] =similarity\n",
    "                    replacement = str(max(sim_dict, key=sim_dict.get))\n",
    "                    new_sentence = new_sentence.replace(token.text,replacement)\n",
    "                elif token.pos_ == 'ADJ':\n",
    "                    sim_dict = {}\n",
    "                    for adj in random.sample(self.inspiring_adjs, self.size_inspiring_adjs_set):\n",
    "                        adj = self.nlp_model(adj)\n",
    "                        similarity = self.nlp_model(token.text).similarity(adj)\n",
    "                        sim_dict[adj] =similarity\n",
    "                    replacement = str(max(sim_dict, key=sim_dict.get))\n",
    "                    new_sentence = new_sentence.replace(token.text,replacement)\n",
    "                elif token.pos_ == 'PROPN':\n",
    "                    sim_dict = {}\n",
    "                    for pprnoun in random.sample(self.inspiring_proper_nouns, self.size_inspiring_proper_nouns_set):\n",
    "                        pprnoun = self.nlp_model(pprnoun)\n",
    "                        similarity = self.nlp_model(token.text).similarity(pprnoun)\n",
    "                        sim_dict[pprnoun] =similarity\n",
    "                    replacement = str(max(sim_dict, key=sim_dict.get))\n",
    "                    new_sentence = new_sentence.replace(token.text,replacement)\n",
    "            if any(token.pos_ in ['NOUN', 'ADJ','PROPN'] for token in doc):\n",
    "                sentences[index] = new_sentence\n",
    "        sentences[0] = '      ' + sentences[0]\n",
    "        str_poem = (\"\\n\".join(sentences))\n",
    "        new_poem = {\"title\": base_poem[\"title\"], \"poem\": str_poem}\n",
    "        return new_poem\n",
    "        \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_poem(text:str)->str:\n",
    "        text = text[0].upper() + text[1:]\n",
    "        text = text[:-1] + '.'\n",
    "        return text \n",
    "    \n",
    "    @staticmethod\n",
    "    def make_poem_title(str_poem:str)-> None:\n",
    "        \"\"\"Makes a title visualisation based on prevalent emotions.\"\"\"\n",
    "        df = pd.DataFrame(te.get_emotion(str_poem),index=[0])\n",
    "        ax = df.plot.barh(stacked=True, color =[\"orange\", \"firebrick\",  \"cyan\",  \"slateblue\", \"thistle\"])\n",
    "        ax.set_axis_off()\n",
    "        ax.patch.set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        ax.get_legend().remove()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def antipoed_poem(self, poem: dict) ->None:\n",
    "        \"\"\"Present individual poem.\"\"\"\n",
    "    \n",
    "        ## gets title (the emotions prevelant) & displays\n",
    "        self.make_poem_title(poem.get('poem'))\n",
    "        display(Markdown(self.format_poem(poem.get('poem'))))\n",
    "    \n",
    "    def antipoed_poetry_collection(self):\n",
    "        \"\"\"Displays anti-poed poetry collection.\"\"\"\n",
    "        \n",
    "        # generate & prepare inspring set\n",
    "        self.prepare_inspiring_set()\n",
    "        \n",
    "        # choose base poems form inspire\n",
    "        df = pd.read_csv(f'poems_'+ self.inspiree.replace('-poems','') + '.csv')\n",
    "        for i in range(self.len_poetry_collection):\n",
    "            poem = df.sample()\n",
    "            self.base_poems.append(self.base_poem_prepare(poem))\n",
    "        \n",
    "        # generate new poems\n",
    "        for i in range(self.len_poetry_collection):\n",
    "            self.new_poems.append(self.antipoed_poem_maker(self.base_poems[i]))\n",
    "        \n",
    "        # display \n",
    "        display(Markdown(\"# \" + self.poetry_collection_name))\n",
    "        image_name = 'wordweb'\n",
    "        display(Image(filename=f'pics/{image_name}.png'))\n",
    "        for new_poem in self.new_poems:\n",
    "            self.antipoed_poem(new_poem)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP = AntiPoed()\n",
    "AP.antipoed_poetry_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Graph\n",
    "\n",
    "The code used to generate the network data (in csv format) for creating the image for the title image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs_sample = random.sample (AP.inspiring_adjs, 300 )\n",
    "matrix_rows = []\n",
    "\n",
    "for token1 in adjs_sample:\n",
    "    row = [AP.nlp_model(token1).similarity(AP.nlp_model(token2)) for token2 in adjs_sample]\n",
    "    matrix_rows.append(row)\n",
    "\n",
    "similarity_matrix = np.array(matrix_rows)\n",
    "df = pd.DataFrame(data = similarity_matrix, columns = adjs_sample, index = adjs_sample)\n",
    "df.to_csv('gephi.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
